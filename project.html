<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ICCN Lab - Research</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <link rel="icon" href="favicon.png" type="image/png">
</head>
<body>
    <header>
        <nav>
            <div class="container">
                <ul>
                    <li><a href="index.html#home"><em>Home</em></a></li>
                    <li><a href="index.html#about"><em>About</em></a></li>
                    <li><a href="index.html#news"><em>News</em></a></li>
                    <li class="active"><a href="team.html"><em>Team</em></a></li> <!-- Active Page -->
                    <li><a href="research.html"><em>Research</em></a></li>
                    <li><a href="project.html"><em>Project</em></a></li>
                    <li><a href="publications.html"><em>Publications</em></a></li>
                    <li><a href="index.html#opportunities"><em>Opportunities</em></a></li>
                    <li><a href="index.html#contact"><em>Contact</em></a></li>
                </ul>
            </div>
        </nav> 

        <div class="container">
            <h1><strong>Intelligent Communication, Computing and Networking Lab</strong></h1>
        </div>
    </header>

    <section id="Project">
        <div class="container">
            <h2>Current Project Topics</h2>
            <hr />
            
            <!-- Project 1: Smart Home Personal Assistant – Emotion-Aware and Contextual IoT Control -->
            <div class="research-area">
                <img src="images/smart_home.png" alt="Smart Home – Emotion-Aware and Contextual Personal Assistant" class="research-image">
                <div class="research-content">
                    <h3>Smart Home – Emotion-Aware and Contextual Personal Assistant</h3>
                    <p>
                        Traditional smart home systems often rely on predefined rules or basic machine learning models, 
                        which struggle to adapt to natural human communication and emotional nuances. To overcome this, 
                        we developed EcoMate, a smart home assistant powered by advanced large language models (LLMs) and integrated with 
                        HomeAssistant. Unlike traditional ML systems that require structured inputs and rigid training, LLMs like GPT-3.5 
                        understand flexible, human-like language and complex context—enabling natural, intuitive conversations with users.
                    </p>
                    <p>
                        EcoMate can interpret not just what users say, but how they say it. 
                        It detects emotional cues from voice and adjusts home devices—like lighting, 
                        temperature, or music—accordingly. For example, if someone sounds stressed, EcoMate 
                        may suggest a break and create a soothing environment. Its ability to learn continuously 
                        from user interactions makes it far more adaptable and user-friendly than fixed-rule or task-specific ML systems. 
                        Pilot users report high satisfaction with EcoMate’s personalized responses and seamless interaction, pointing to a more intelligent and emotionally aware future for smart homes.
                    </p>
                </div>
            </div>
            <hr />
            <hr />
            
            <!-- Project 2: Wildfire Early Detection – UAV-Satellite Multimodal Forecasting System -->
            <div class="research-area">
                <img src="images/wildfire.png" alt="Wildfire Early Detection – UAV-Satellite Forecasting System" class="research-image">
                <div class="research-content">
                    <h3>Wildfire Early Detection – UAV-Satellite Forecasting System</h3>
                    <p>
                        Wildfires now threaten over 400 million hectares globally each year, causing immense environmental and economic damage.
                         Many fire-prone areas—especially in remote boreal zones—lack adequate ground-based sensing or rapid-response systems. 
                         To address this market gap, our project introduces an integrated surveillance solution combining unmanned aerial vehicles (UAVs) 
                         with satellite and environmental data. UAVs act as mobile surveillance units, capable of accessing regions where human 
                         deployment is impractical, and autonomously collecting localized multimodal data to complement satellite observations.
                    </p>
                    <p>                         
                         To accommodate the UAVs’ limited onboard resources, we implement a collaborative AI deployment strategy: 
                         lightweight model components operate on the UAVs, while more intensive processing is handled by the control center. 
                         This setup ensures energy-efficient operation while enabling timely forecasts. As the UAVs continuously gather data, 
                         a dynamic database is maintained at the control center to support continuous model updating and adaptation to evolving 
                         wildfire patterns. The system provides valuable support for early intervention and strategic planning, aiming to reduce 
                         fire response times and limit large-scale fire spread.
                    </p>
                
                </div>
            </div>
            <hr />
            <hr />
            
            
            <!-- Project 3: Smart Agriculture – UAV-Based Pest & Disease Detection -->
            <div class="research-area">
                <img src="images/smart_algo.png" alt="Smart Agriculture – UAV-Based Pest & Disease Detection" class="research-image">
                <div class="research-content">
                    <h3>Smart Agriculture – UAV-Based Pest & Disease Detection</h3>
                    <p>
                       As global food demand rises and labor costs increase, 
                       conventional pest scouting covers only ~5–10% of fields—leaving vast blind spots that drive crop losses and pesticide overuse.
                       Despite this urgency, industry lacks scalable, autonomous detection systems that can pinpoint early infestations across large acreages.
                       To address this critical challenge, we developed an autonomous UAV-based system that surveys fields at scale and detects early signs of crop threats using onboard vision and intelligence.

                       By combining high-resolution aerial imagery with robust AI models, our solution enables fast, 
                       accurate identification of pests, diseases, and weeds—down to the plant level. In field pilots, 
                       this system reduced inspection time per acre from hours to minutes, while improving detection precision.
                        As a result, farmers achieved up to 30% reduction in pesticide usage, 20% yield improvement, 
                        and significantly lower operating costs. This approach offers a scalable path toward more sustainable, 
                        efficient, and resilient agriculture.
                    </p>
                </div>
            </div>
            <hr />
            <hr />

            <!-- Project 4: Smart City – Intelligent Traffic Management System -->
            <div class="research-area">
                <img src="images/smart_trans.png" alt="Smart Transportation – UAV-Assisted Intersection Safety System" class="research-image">
                <div class="research-content">
                    <h3>Smart Transportation – UAV-Assisted Intersection Safety System</h3>
                    <p>
                       Urban intersections are hotspots for accidents, especially in mixed-traffic zones involving bicycles, scooters, and other micro-mobility vehicles. 
                       Many of these systems lack real-time situational awareness, leading to frequent near-misses and collisions. 
                       In collaboration with Bemini Bikes, we are developing a UAV-assisted smart transportation system to enhance safety at intersections.
                    </p>
                    <p>
                        UAVs serve as aerial surveillance units, continuously monitoring intersections and detecting traffic flow from above. 
                        This data is processed and shared in real time, allowing each transportation unit to become aware of others nearby. 
                        When a potential collision risk is identified, the system sends alerts directly to users' smartphones, enabling timely reactions. 
                        Designed for easy integration into existing urban infrastructure, the system promotes safer, smarter traffic coordination and a more connected mobility experience.
                    </p>
                </div>

        </div>
    </section>

    <footer>
        <div class="container">
            <p>&copy; Intelligent Communication, Computing and Networking Lab. All Rights Reserved.</p>
            <div class="social">
                <a href="#"><i class="fab fa-linkedin"></i></a>
                <a href="#"><i class="fab fa-twitter"></i></a>
                <a href="#"><i class="fab fa-github"></i></a>
            </div>
        </div>
    </footer>
    <script src="script.js"></script>
</body>
</html>
